{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52847ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Automated Dispersion Compensation Network (ADC-Net).\n",
    "This file contains the code to train ADC-Net. For this example, a 5 input model will be demonstrated.\n",
    "Minor modifications is needed for the other types of input models.\n",
    "@author: dleninja\n",
    "\"\"\"\n",
    "#\n",
    "import tensorflow as tf\n",
    "#\n",
    "\"\"\"\n",
    "For machines with dedicated GPU(s), utilize the GPU for tensorflow training\n",
    "\"\"\"\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "#\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import img_as_float, transform, exposure, io, color\n",
    "from pathlib import Path\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#\n",
    "from model import *\n",
    "from custom_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269ceb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the ADCNet model, dependent on the functions defined in model.py\n",
    "\"\"\"\n",
    "#\n",
    "model = adcnet_model(block=[6, 12, 24, 16], height=608, width=320, n_channels=5)\n",
    "# model.summary() # Very deep network architecture. If you would like to see the model, feel free to uncomment.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e40d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import the DenseNet121 pre-trained weights from the ImageNet dataset into the encoder of ADCNet\n",
    "\"\"\"\n",
    "#\n",
    "densenet_model = tf.keras.applications.DenseNet121(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    )\n",
    "weights = [layer.get_weights() for layer in densenet_model.layers[5:427]]\n",
    "for layer, weight in zip(model.layers[5:427], weights):\n",
    "    layer.set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7e8594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile the Model, dependent on the loss function defined in custom_utils.py\n",
    "\"\"\"\n",
    "#\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=0.0001),\n",
    "    loss = SSIMLoss,\n",
    "    metrics = [\"acc\"]\n",
    ")\n",
    "#\n",
    "batch_size = 16\n",
    "#\n",
    "export_dir = Path(\"Results\")\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "#\n",
    "model_file_format = os.path.join(\n",
    "    export_dir, \n",
    "    \"dispersion_model.{epoch:03d}.hdf5\"\n",
    ")\n",
    "checkpointer = ModelCheckpoint(\n",
    "    model_file_format,\n",
    "    period = 1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f554730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/imageio/plugins/_tifffile.py:7285: UserWarning: partially initialized module 'imageio.plugins._tifffile' has no attribute 'decode_packbits' (most likely due to a circular import)\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n",
      "/usr/lib/python3/dist-packages/imageio/plugins/_tifffile.py:7285: UserWarning: partially initialized module 'imageio.plugins._tifffile' has no attribute 'decode_lzw' (most likely due to a circular import)\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n",
      "/usr/lib/python3/dist-packages/imageio/plugins/_tifffile.py:7285: UserWarning: partially initialized module 'imageio.plugins._tifffile' has no attribute 'unpack_ints' (most likely due to a circular import)\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n",
      "/usr/lib/python3/dist-packages/imageio/plugins/_tifffile.py:7285: UserWarning: partially initialized module 'imageio.plugins._tifffile' has no attribute 'reverse_bitorder' (most likely due to a circular import)\n",
      "  Functionality might be degraded or be slow.\n",
      "\n",
      "  warnings.warn(\"%s%s\" % (e, warn))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Images loaded --- \n",
      "\t(672, 608, 320, 5)\n",
      " --- Images loaded --- \n",
      "\t(672, 608, 320, 1)\n",
      " --- Images loaded --- \n",
      "\t(168, 608, 320, 5)\n",
      " --- Images loaded --- \n",
      "\t(168, 608, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import the dataset. For our implementation purposes, we will be directly loading the data by a custom imageloader\n",
    "Dependent on the function in custom_utils.py\n",
    "\"\"\"\n",
    "#\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "n_train = int(len(df)*0.8)\n",
    "#\n",
    "df_train = df[:n_train]\n",
    "df_train = df_train.sample(frac=1)\n",
    "#\n",
    "df_valid = df[n_train:]\n",
    "df_valid = df_valid.sample(frac=1)\n",
    "#\n",
    "path1 = Path(\"dataset/magnitude1\")\n",
    "path2 = Path(\"dataset/magnitude3\")\n",
    "path3 = Path(\"dataset/magnitude5\")\n",
    "path4 = Path(\"dataset/magnitude7\")\n",
    "path5 = Path(\"dataset/magnitude9\")\n",
    "path6 = Path(\"dataset/compensated\")\n",
    "#\n",
    "path_list_X = [path1, path2, path3, path4, path5]\n",
    "path_list_y = [path6]\n",
    "#\n",
    "im_shape = (608, 320)\n",
    "#\n",
    "X_train = load_multichannel_image(df_train, im_shape, path_list_X, 0)\n",
    "y_train = load_multichannel_image(df_train, im_shape, path_list_y, 0)\n",
    "#\n",
    "X_valid = load_multichannel_image(df_valid, im_shape, path_list_X, 0)\n",
    "y_valid = load_multichannel_image(df_valid, im_shape, path_list_y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c54c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 15:16:28.629254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-01 15:16:29.709341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 22s 526ms/step - loss: 0.8509 - acc: 0.0108 - val_loss: 0.9370 - val_acc: 0.0037\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 19s 464ms/step - loss: 0.6917 - acc: 0.0084 - val_loss: 0.9303 - val_acc: 0.0040\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 20s 472ms/step - loss: 0.6019 - acc: 0.0088 - val_loss: 0.9181 - val_acc: 0.0038\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 19s 457ms/step - loss: 0.5632 - acc: 0.0074 - val_loss: 0.9236 - val_acc: 0.0034\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 19s 458ms/step - loss: 0.5379 - acc: 0.0078 - val_loss: 0.9237 - val_acc: 0.0034\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 19s 457ms/step - loss: 0.5181 - acc: 0.0081 - val_loss: 0.9354 - val_acc: 0.0017\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 19s 458ms/step - loss: 0.5003 - acc: 0.0084 - val_loss: 0.9241 - val_acc: 0.0033\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 20s 468ms/step - loss: 0.4817 - acc: 0.0089 - val_loss: 0.9029 - val_acc: 0.0038\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 20s 468ms/step - loss: 0.4625 - acc: 0.0095 - val_loss: 0.8800 - val_acc: 0.0034\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 19s 458ms/step - loss: 0.4466 - acc: 0.0090 - val_loss: 0.9442 - val_acc: 5.0034e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea24466400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the model\n",
    "\"\"\"\n",
    "#\n",
    "model.fit(X_train, y_train, batch_size, \n",
    "    steps_per_epoch = n_train // batch_size,\n",
    "    validation_data = (X_valid, y_valid),\n",
    "    callbacks = [checkpointer],\n",
    "    epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcd5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
